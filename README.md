# LangChain Meta-Agent System

An advanced **meta-orchestration system** that dynamically creates hierarchical multi-agent workflows based on query complexity. Built with LangChain, Ollama (local LLM), and Arize Phoenix observability.

## ğŸŒŸ Key Features

### Intelligent Orchestration
- **ğŸ¯ Adaptive Complexity Analysis**: Automatically analyzes query complexity (score-based system)
- **ğŸ“Š Dynamic Scaling**: Scales from 1 agent (simple) to 12+ agents (complex projects)
- **ğŸ”€ Hierarchical Delegation**: Up to 5 levels of agent nesting with recursive task delegation
- **ğŸ§  Meta-Coordination**: AI coordinator decides optimal agent topology per query

### Agent Capabilities
- **8 Specialized Roles**: Researcher, Analyzer, Planner, Writer, Coder, Critic, Synthesizer, Coordinator
- **ğŸ”§ Tool Integration**: DuckDuckGo web search for real-time information
- **ğŸ¨ Role-Based Delegation**: Planner and Coordinator roles can spawn sub-agents
- **ğŸ’¾ Conversation Memory**: Maintains context across multi-turn conversations

### Visualization & Monitoring
- **ğŸŒ³ Terminal Trees**: Rich console output showing execution hierarchy
- **ğŸŒ Interactive Graphs**: PyVis-based HTML graphs with hover details
- **ğŸ“ˆ Phoenix Tracing**: Real-time observability with unique trace names per agent
- **ğŸ“Š Complexity Insights**: Detailed logging of complexity analysis and decisions

### Technical Stack
- **ğŸ¤– Local LLM**: Ollama (llama3.2:1b) - 100% local, no API calls
- **ğŸ” Web Search**: DuckDuckGo Search integration
- **ğŸ“Š Observability**: Arize Phoenix with OpenTelemetry instrumentation
- **ğŸ¨ Visualization**: Rich (terminal) + PyVis (interactive graphs)

## ğŸ—ï¸ Architecture

### Complexity-Based Execution

The system analyzes each query and assigns a complexity score based on:
- Multi-step indicators (plan, design, create, build, comprehensive...)
- Analysis keywords (compare, evaluate, research, analyze...)
- Query length and structure
- Multiple question marks or "and" conjunctions

**Complexity Mapping:**
```
Score < 1:    Very Simple  â†’ depth=1, 1-2 agents
Score 1-2:    Simple       â†’ depth=2, 2-4 agents  
Score 3-4:    Moderate     â†’ depth=3, 4-6 agents
Score 5-7:    Complex      â†’ depth=4, 6-8 agents
Score 8+:     Very Complex â†’ depth=5, 8-12+ agents
```

### Hierarchical Agent System

```
Level 0: User Query
â”œâ”€ Meta-Coordinator (analyzes & plans)
â”œâ”€ Agent 1: Coordinator [can delegate]
â”‚  â””â”€ Level 1: Sub-query
â”‚     â”œâ”€ Sub-Agent 1.1: Researcher
â”‚     â”œâ”€ Sub-Agent 1.2: Analyzer
â”‚     â””â”€ Sub-Agent 1.3: Synthesizer
â”œâ”€ Agent 2: Writer
â””â”€ Agent 3: Synthesizer
```

### Execution Flow

1. **Query Analysis** â†’ Complexity scoring (automated)
2. **Meta-Planning** â†’ Coordinator designs agent topology
3. **Agent Execution** â†’ Sequential/hierarchical execution
4. **Delegation** (if needed) â†’ Recursive sub-agent creation
5. **Synthesis** â†’ Final answer compilation
6. **Visualization** â†’ Graphs and traces

## ğŸ“¦ Prerequisites

- **Python 3.11+**
- **Ollama** - [Download from ollama.com](https://ollama.com)

## ğŸš€ Quick Start

### 1. Install Ollama & Model
```bash
# Install Ollama, then pull the model
ollama pull llama3.2:1b
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Run the Application
```bash
python -m src.main
```

### 4. Access Phoenix Dashboard
Open http://localhost:6006 in your browser to see real-time traces.

## ğŸ’¡ Usage Examples

### Simple Query (1 agent)
```
â“ Your question: What is Python?

ğŸ“Š Complexity: Very Simple (score: 0.0) â†’ max_depth: 1
ğŸ“‹ Execution Plan (max depth: 1): Direct explanation
â”œâ”€â”€ ğŸ¤– Step 1: ANALYZER
    â””â”€â”€ Task: Explain what Python is
```

### Moderate Query (4-6 agents)
```
â“ Your question: Plan a 3-day trip to Paris with budget

ğŸ“Š Complexity: Moderate (score: 3.5) â†’ max_depth: 3
ğŸ“‹ Execution Plan (max depth: 3): Travel planning
â”œâ”€â”€ ğŸ¤– Step 1: RESEARCHER
â”œâ”€â”€ ğŸ¤– Step 2: PLANNER
â”œâ”€â”€ ğŸ¤– Step 3: ANALYZER
â”œâ”€â”€ ğŸ¤– Step 4: WRITER
â””â”€â”€ ğŸ¤– Step 5: SYNTHESIZER
```

### Complex Query (8+ agents with delegation)
```
â“ Your question: Create a comprehensive business plan with market research, financial projections, and marketing strategy

ğŸ“Š Complexity: Very Complex (score: 11.5) â†’ max_depth: 5
ğŸ“‹ Execution Plan (max depth: 5): Business planning
â”œâ”€â”€ ğŸ¤– Step 1: COORDINATOR ğŸ”€ [can delegate]
â”‚   â””â”€â”€ [Delegates to 6 sub-agents]
â””â”€â”€ ğŸ¤– Step 2: SYNTHESIZER
```

## ğŸ® Interactive Commands

| Command | Description |
|---------|-------------|
| `quit` / `exit` | Exit application |
| `memory` | Show conversation history summary |
| `show-memory` | Display detailed conversation table |
| `clear` | Clear conversation memory |
| Graph prompt | Generate interactive HTML graph after each query |

## ğŸ“Š Visualization

### Terminal Output
- **Rich Tree**: Hierarchical plan visualization
- **Progress Tables**: Real-time execution status
- **Complexity Analysis**: Detailed scoring breakdown

### Interactive Graphs
- **PyVis Network**: Saved to `execution_graphs/`
- **Node Colors**: Role-based (researcher=blue, planner=orange, etc.)
- **Hover Details**: Task, status, output preview
- **Auto-Open**: Browser opens automatically (optional)

## ğŸ”§ Configuration

Create `.env` file (optional):
```bash
OLLAMA_MODEL=llama3.2:1b
OLLAMA_TEMPERATURE=0.7
PHOENIX_PORT=6006
LOG_LEVEL=INFO
```

## ğŸ“š Role Library

| Role | Description | Can Delegate |
|------|-------------|--------------|
| **Researcher** | Web search, fact-finding | âŒ |
| **Analyzer** | Data analysis, comparisons | âŒ |
| **Planner** | Strategic planning | âœ… |
| **Writer** | Content creation | âŒ |
| **Coder** | Code generation | âŒ |
| **Critic** | Quality review | âŒ |
| **Synthesizer** | Result compilation | âŒ |
| **Coordinator** | Workflow management | âœ… |

## ğŸ¯ Use Cases

- **Simple Q&A**: Direct answers (1-2 agents)
- **Research Tasks**: Web search + analysis (3-4 agents)
- **Planning**: Multi-step strategies (4-6 agents)
- **Content Creation**: Research + write + review (5-7 agents)
- **Complex Projects**: Hierarchical delegation (8-12+ agents)

## ğŸ“– Documentation

- [HIERARCHICAL_AGENTS.md](HIERARCHICAL_AGENTS.md) - Deep dive into multi-layer architecture
- [VISUALIZATION.md](VISUALIZATION.md) - Visualization features and usage

## ğŸ” Observability

**Arize Phoenix Dashboard** (http://localhost:6006):
- **Traces Tab**: See all LLM calls with unique names
- **Metadata**: Agent role, task, depth level
- **Tags**: Filter by role, operation type
- **Timeline**: Execution flow visualization

## ğŸ› ï¸ Project Structure

```
test_langchain/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                    # Interactive CLI
â”‚   â”œâ”€â”€ meta_agent_system.py       # Core orchestration engine
â”‚   â”œâ”€â”€ meta_coordinator.py        # AI-based planning
â”‚   â”œâ”€â”€ role_library.py            # Agent role definitions
â”‚   â”œâ”€â”€ tools.py                   # DuckDuckGo search tools
â”‚   â”œâ”€â”€ visualization.py           # Rich + PyVis rendering
â”‚   â”œâ”€â”€ observability.py           # Phoenix tracing
â”‚   â””â”€â”€ config.py                  # Configuration
â”œâ”€â”€ execution_graphs/              # Generated HTML graphs
â”œâ”€â”€ requirements.txt               # Dependencies
â”œâ”€â”€ HIERARCHICAL_AGENTS.md         # Architecture docs
â”œâ”€â”€ VISUALIZATION.md               # Visualization guide
â””â”€â”€ README.md                      # This file
```

## ğŸš¨ Troubleshooting

### "Ollama connection failed"
```bash
# Start Ollama server
ollama serve

# Verify model is available
ollama list
ollama pull llama3.2:1b
```

### "Phoenix not starting"
```bash
# Port 6006 might be in use
# Change PHOENIX_PORT in .env or:
export PHOENIX_PORT=6007
python -m src.main
```

### "No delegation happening"
- Check if query complexity score is high enough (>3)
- Verify coordinator role has `can_delegate=True`
- Look for delegation JSON in agent output logs

## ğŸ“ˆ Performance Notes

- **llama3.2:1b**: Fast inference (~1-2s per agent)
- **Scaling**: Up to 12 agents tested successfully
- **Memory**: 4GB RAM recommended for complex workflows
- **Storage**: HTML graphs are ~100KB each

## ğŸ”® Future Enhancements

- [ ] Custom role creation from CLI
- [ ] Persistent memory database (SQLite)
- [ ] Multi-model support (different LLMs per role)
- [ ] Agent learning from feedback
- [ ] Parallel agent execution
- [ ] Cost tracking and optimization

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ™ Acknowledgments

Built with:
- [LangChain](https://github.com/langchain-ai/langchain) - Agent orchestration
- [Ollama](https://ollama.com) - Local LLM runtime
- [Arize Phoenix](https://github.com/Arize-ai/phoenix) - Observability
- [Rich](https://github.com/Textualize/rich) - Terminal UI
- [PyVis](https://github.com/WestHealth/pyvis) - Network graphs

---

**Built with â¤ï¸ for adaptive AI agent systems**
